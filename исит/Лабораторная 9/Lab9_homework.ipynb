{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ЛАБОРАТОРНАЯ РАБОТА 9. ИСПОЛЬЗОВАНИЕ РАЗРАБОТАННОГО ПАЙПЛАЙНА ДЛЯ МНОГОМЕРНОЙ РЕГРЕССИИ\n",
        "\n",
        "Цели и задачи\n",
        "\n",
        "Цель лабораторной работы: научиться применять разработанный пайплайн для тиражирования кода с целью решения широкого круга задач машинного обучения.\n",
        "Основные задачи:\n",
        "–\tполучение навыков рефакторинга кода в проектах машинного обучения;\n",
        "–\tполучение навыков определения ключевых признаков в задачах машинного обучения;\n",
        "–\tполучение навыков реализации ключевых стратегий оптимизации моделей регрессии.\n",
        "\n",
        "Теоретическое обоснование\n",
        "При решении задач многомерной регресси исследователю необходимо решить ряд подзадач:\n",
        "1.\tОпределить коррелированность признаков.\n",
        "2.\tОпределить, какие признаки существенны при построении модели регрессии.\n",
        "Проблема определения значимых признаков мвязана с проблемой снижения размерности.\n",
        "Важное значение при многомерной регресси приобретает обработка категориальных признаов. Часто необходимо заменить категориальный признак на набор фиктивных переменных.\n",
        "К проблеме выбора значимых переменных существует несколько стратегий (фактически это методы построения модели многомерной регрессии):\n",
        "1.\tAll-in. В данном подходе производится включение веех признаков в модель.\n",
        "2.\tBackward Elimination. В подходе предполагается обучение модели с учетом всех признаков и удаление признаков по одному на основе их значимости до достижения ситуации, когда останутся только значимые признаки.\n",
        "3.\tForward Selection. Подход предполагает начальное тестирование модели с одним признаком (тестируется каждый признак). Затем добавляются по одному наиболее значимые признаки.\n",
        "4.\tBidirectional Elimination. Подход совмещает стратегии 2 и 3.\n",
        "5.\tScore Comparison.\n",
        "\n",
        "Оборудование и материалы\n",
        "\n",
        "Для выполнения лабораторной работы рекомендуется использовать персональный компьютер со следующими программными средствами разработки (выбрать один или несколько програмных продуктов для практической реализации задач лабораторной работы): MS Visual Studio 2013 и выше; среда разработки Java, интерпретатор Python (Jupyter Notebook).\n",
        "\n",
        "Методика и порядок выполнения работы\n",
        "\n",
        "Перед выполнением индивидуального задания рекомендуется выполнить все пункты учебной задачи.\n",
        "\n",
        "Постановка задачи.\n",
        "Задание. На основе разработанного пайплайна для линейной одномерной регрессии разработать многомерную модель регрессии.\n",
        "Решение. Для разработки модели необходимо реализовать следующий код:\n"
      ],
      "metadata": {
        "id": "dpbrvLEFXNZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwn4x93RXHKK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('50_Startups.csv')\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "0AfKO1NkirRn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "26e7cc88-16da-4e02-9919-e9bb395bdccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
              "0  165349.20       136897.80        471784.10    New York  192261.83\n",
              "1  162597.70       151377.59        443898.53  California  191792.06\n",
              "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
              "3  144372.41       118671.85        383199.62    New York  182901.99\n",
              "4  142107.34        91391.77        366168.42     Florida  166187.94"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4051602a-5b1c-4918-a8c4-91cacf9ccada\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>State</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165349.20</td>\n",
              "      <td>136897.80</td>\n",
              "      <td>471784.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>192261.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162597.70</td>\n",
              "      <td>151377.59</td>\n",
              "      <td>443898.53</td>\n",
              "      <td>California</td>\n",
              "      <td>191792.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153441.51</td>\n",
              "      <td>101145.55</td>\n",
              "      <td>407934.54</td>\n",
              "      <td>Florida</td>\n",
              "      <td>191050.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>144372.41</td>\n",
              "      <td>118671.85</td>\n",
              "      <td>383199.62</td>\n",
              "      <td>New York</td>\n",
              "      <td>182901.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142107.34</td>\n",
              "      <td>91391.77</td>\n",
              "      <td>366168.42</td>\n",
              "      <td>Florida</td>\n",
              "      <td>166187.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4051602a-5b1c-4918-a8c4-91cacf9ccada')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4051602a-5b1c-4918-a8c4-91cacf9ccada button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4051602a-5b1c-4918-a8c4-91cacf9ccada');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97c8b0e9-a42a-422f-b60d-1928314f27cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97c8b0e9-a42a-422f-b60d-1928314f27cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97c8b0e9-a42a-422f-b60d-1928314f27cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"R&D Spend\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45902.25648230753,\n        \"min\": 0.0,\n        \"max\": 165349.2,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          91992.39,\n          1000.23,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Administration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28017.802755488683,\n        \"min\": 51283.14,\n        \"max\": 182645.56,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          135495.07,\n          82982.09,\n          115641.28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Marketing Spend\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122290.31072584528,\n        \"min\": 0.0,\n        \"max\": 471784.1,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          353183.81,\n          172795.67,\n          134050.07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"California\",\n          \"Florida\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40306.18033765055,\n        \"min\": 14681.4,\n        \"max\": 192261.83,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          134307.35,\n          81005.76,\n          99937.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 4].values\n",
        "print (\"Матрица признаков\"); print(X[:5])\n",
        "print (\"Зависимая переменная\"); print(y[:5])"
      ],
      "metadata": {
        "id": "zjmYDEqpi0PM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5128ba6e-9297-4d1c-a1d9-07d72f42da08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Матрица признаков\n",
            "[[165349.2 136897.8 471784.1 'New York']\n",
            " [162597.7 151377.59 443898.53 'California']\n",
            " [153441.51 101145.55 407934.54 'Florida']\n",
            " [144372.41 118671.85 383199.62 'New York']\n",
            " [142107.34 91391.77 366168.42 'Florida']]\n",
            "Зависимая переменная\n",
            "[192261.83 191792.06 191050.39 182901.99 166187.94]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import Imputer\n",
        "# imputer = Imputer(missing_values = 'NaN', strategy = 'mean\", axis = 0)\n",
        "# imputer = imputer.fit(X(:, 1:3])\n",
        "# X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
        "# print(X)"
      ],
      "metadata": {
        "id": "GXH-Mg1Mi-IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# Labelencoder_y = LabelEncoder()\n",
        "# print(\"Зависимая переменная до обработки\")\n",
        "# print(y)\n",
        "# y = Labelencoder_y.fit_transform(y)\n",
        "# print(\"Зависимая переменная после обработки\")\n",
        "# print(y)"
      ],
      "metadata": {
        "id": "vjg0zurjjHcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
        "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
        "X = onehotencoder.fit_transform(X).toarray()\n",
        "print(\"Перекодировка категориального признака\")\n",
        "print(X[:4,:])"
      ],
      "metadata": {
        "id": "q2pHZl_ijQWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "0a577a47-8ca1-4c6f-98ae-14c6a193d010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-0b5c5dd7eacf>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabelencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0monehotencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehotencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mEncoded\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \"\"\"\n\u001b[1;32m   1218\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m     y = check_array(\n\u001b[0m\u001b[1;32m   1220\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m         array = _ensure_sparse_format(\n\u001b[0m\u001b[1;32m    882\u001b[0m             \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34m\"A sparse matrix was passed, but dense \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"data is required. Use X.toarray() to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.5 Для предотвращения мультиколлинеарности необходимо избавиться от одной из\n",
        "фиктивных переменных, добавленных в результате обработки категориальных признаков"
      ],
      "metadata": {
        "id": "dMygue9AjYFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[:, 1:]\n",
        "print(X[:4,:])"
      ],
      "metadata": {
        "id": "mLvT-SvDjYWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44bec6ee-cfda-4c37-ccf2-a82cc1e72142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 46)\t1.0\n",
            "  (0, 47)\t1.0\n",
            "  (0, 48)\t165349.2\n",
            "  (0, 49)\t136897.8\n",
            "  (0, 50)\t2.0\n",
            "  (1, 45)\t1.0\n",
            "  (1, 47)\t1.0\n",
            "  (1, 48)\t162597.7\n",
            "  (1, 49)\t151377.59\n",
            "  (2, 44)\t1.0\n",
            "  (2, 47)\t1.0\n",
            "  (2, 48)\t153441.51\n",
            "  (2, 49)\t101145.55\n",
            "  (2, 50)\t1.0\n",
            "  (3, 43)\t1.0\n",
            "  (3, 47)\t1.0\n",
            "  (3, 48)\t144372.41\n",
            "  (3, 49)\t118671.85\n",
            "  (3, 50)\t2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.6 Разделение выборки на тестовую и тренировочную"
      ],
      "metadata": {
        "id": "FuGqESItjgP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "DxpFtoYNjgeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.7 Обучение линейной модели регрессии"
      ],
      "metadata": {
        "id": "pLdRTBUVjrwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "QfmLE6QAjsDo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "18a49193-dbdc-4b33-8bc2-8c269edc3407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.8 Обработка результатов, тюнинг модели\n",
        "1.8.1 Предсказание"
      ],
      "metadata": {
        "id": "P7ZAzLgpj1P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "AZxz-ZUXj1lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f142ce7-7653-493d-f858-3d9ff65e67ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[106089.73770857 130424.38265073 134561.34506938  70695.70372686\n",
            " 178218.7080079  112183.12223787  66143.68960505 103554.33452411\n",
            " 111113.87260284 168270.33210981]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На данный момент произведено обучение модели на всем наборе признаков. Для оптимизации модели реализуем стратегию Back Elimination (рисунк 9.2)."
      ],
      "metadata": {
        "id": "qG6n3No4j5Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as sm\n",
        "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n",
        "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
        "regressor_OLS.summary()"
      ],
      "metadata": {
        "id": "R0F1_m8jj6PP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "b7235938-6993-4702-f804-f1c2bb11c59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 0 dimension(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-54159bfad972>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mregressor_OLS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5616\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5617\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5618\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 0 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt = X[:, [0, 1, 3, 4, 5]]\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
        "regressor_OLS.summary()"
      ],
      "metadata": {
        "id": "t2a2NiZikDZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b57f3423-9767-43bf-a25a-ad09a821ec47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'statsmodels.formula.api' has no attribute 'OLS'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c58a38b36745>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregressor_OLS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'statsmodels.formula.api' has no attribute 'OLS'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt = X[:, [0, 3, 4, 5]]\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
        "regressor_OLS.summary()"
      ],
      "metadata": {
        "id": "jpx_OCjUkPMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "6c8524d7-ccb0-47c3-f0ca-f6237c080193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'statsmodels.formula.api' has no attribute 'OLS'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-42c3c05fa314>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregressor_OLS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'statsmodels.formula.api' has no attribute 'OLS'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt = X[:, [0, 3, 5]]\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
        "regressor_OLS.summary()"
      ],
      "metadata": {
        "id": "BXJqe9TVkIms",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c969026a-eba1-4ba8-8f21-1e39b846a4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 5 is out of bounds for axis 1 with size 5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9cc48108086d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mregressor_OLS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_opt = X[:, [0, 3]]\n",
        "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
        "regressor_OLS.summary()"
      ],
      "metadata": {
        "id": "wlE21InikPxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "4f250249-2c7d-4e03-be92-e9417825341e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'statsmodels.formula.api' has no attribute 'OLS'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1e0015f517eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregressor_OLS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'statsmodels.formula.api' has no attribute 'OLS'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполните индивидуальное задание.\n",
        "\n",
        "Индивидуальное задание\n",
        "1.\tПодберите набор данных на ресурсах [5-7] и согласуйте свой выбор с преподавателем. Студент может предложить набор данных в соответствии с тематикой магистерского исследования.\n",
        "2.\tПостройте модель многомерной регрессии с использованием стратегии backward elimination.\n",
        "\n",
        "Содержание отчета и его форма\n",
        "\n",
        "Отчет по лабораторной работе должен содержать:\n",
        "1.\tНомер и название лабораторной работы; задачи лабораторной работы.\n",
        "2.\tРеализация каждого пункта подраздела «Индивидуальное задание» с приведением исходного кода программы, диаграмм и графиков для визуализации данных.\n",
        "3.\tОтветы на контрольные вопросы.\n",
        "\n",
        "4.\tЭкранные формы (консольный вывод) и листинг программного кода с комментариями, показывающие порядок выполнения лабораторной работы, и результаты, полученные в ходе её выполнения.\n",
        "Отчет о выполнении лабораторной работы сдается преподавателю.\n",
        "\n",
        "Контрольные вопросы\n",
        "\n",
        "1.\tПочему при реализации многомерной линейной регрессии необходимо добавить фиктивный признак с единственным значением 1.0?.\n",
        "2.\tто такое фиктивная переменная? Поясните причину удаления одной фиктивной переменной, возникающей при перекодировке категориального признака.\n",
        "3.\tНа основе какого критерия можно выбирать удаляемый признак в алгоритме back elimination.\n",
        "4.\tВ чем заключается алгоритм all-in regression?\n",
        "5.\tВ чем заключается алгоритм forward selection regression?\n",
        "6.\tВ чем заключается алгоритм Bidirectional Elimination?\n",
        "7.\tСтратегия Backward Elimination предполагает удаление признаков на основе анализа p-критерия. Как реализовать удаление признаков в автоматическом режиме?\n",
        "\n",
        "Список литературы\n",
        "\n",
        "Для выполнения лабораторной работы, при подготовке к защите, а также для ответа на контрольные вопросы рекомендуется использовать следующие\n",
        "источники: [1, 2, 5-7].\n",
        "\n"
      ],
      "metadata": {
        "id": "GdXk3V4OkWbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z2jeWh0ikWTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Vk1EifKw8hxB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "data = pd.read_csv('1.benign.csv')\n",
        "\n",
        "# Просмотр первых строк данных\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1GPFYeA8qLa",
        "outputId": "e9d8d58b-bc6c-43d8-8c7b-fb30bcaf88e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
            "0          1.000000       60.000000            0.000000          1.000000   \n",
            "1          1.000000      354.000000            0.000000          1.000000   \n",
            "2          1.857879      360.458980           35.789338          1.912127   \n",
            "3          1.000000      337.000000            0.000000          1.000000   \n",
            "4          1.680223      172.140917        18487.448750          1.793580   \n",
            "\n",
            "   MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
            "0       60.000000            0.000000          1.000000       60.000000   \n",
            "1      354.000000            0.000000          1.000000      354.000000   \n",
            "2      360.275733           35.923972          1.969807      360.091968   \n",
            "3      337.000000            0.000000          1.000000      337.000000   \n",
            "4      182.560279        18928.175300          1.925828      193.165753   \n",
            "\n",
            "   MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  \\\n",
            "0            0.000000            1.000000  ...          0.000000   \n",
            "1            0.000000            1.000000  ...         34.095047   \n",
            "2           35.991542            1.996939  ...        100.081513   \n",
            "3            0.000000            1.000000  ...          0.000000   \n",
            "4        19153.795810            1.992323  ...          0.000000   \n",
            "\n",
            "   HpHp_L0.1_covariance  HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  \\\n",
            "0                   0.0            0.0           1.000000        60.000000   \n",
            "1                   0.0            0.0           5.319895       344.262695   \n",
            "2                   0.0            0.0           6.318264       347.703087   \n",
            "3                   0.0            0.0           1.000000       337.000000   \n",
            "4                   0.0            0.0           1.000000        60.000000   \n",
            "\n",
            "   HpHp_L0.01_std  HpHp_L0.01_magnitude  HpHp_L0.01_radius  \\\n",
            "0        0.000000             60.000000           0.000000   \n",
            "1        4.710446            344.262695          22.188299   \n",
            "2        9.034660            347.703087          81.625077   \n",
            "3        0.000000            337.000000           0.000000   \n",
            "4        0.000000             60.000000           0.000000   \n",
            "\n",
            "   HpHp_L0.01_covariance  HpHp_L0.01_pcc  \n",
            "0                    0.0             0.0  \n",
            "1                    0.0             0.0  \n",
            "2                    0.0             0.0  \n",
            "3                    0.0             0.0  \n",
            "4                    0.0             0.0  \n",
            "\n",
            "[5 rows x 115 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение целевой переменной и признаков\n",
        "X = data.drop('MI_dir_L5_weight', axis=1)  # Замените 'target_variable' на название вашей целевой переменной\n",
        "y = data['target_variable']  # Замените 'target_variable' на название вашей целевой переменной\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "7Rft_DQS8twA",
        "outputId": "49c7b193-6001-4e19-e142-2a05c91f742b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['target_variable'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6a2f1284a6ee>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Определение целевой переменной и признаков\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target_variable'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Замените 'target_variable' на название вашей целевой переменной\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_variable'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Замените 'target_variable' на название вашей целевой переменной\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['target_variable'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Qr0Sqp708uzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для выполнения Backward Elimination\n",
        "def backward_elimination(X, y, significance_level=0.05):\n",
        "    # Добавляем константу (свободный член) к признакам\n",
        "    X = sm.add_constant(X)\n",
        "\n",
        "    # Начальная модель\n",
        "    model = sm.OLS(y, X).fit()\n",
        "\n",
        "    while True:\n",
        "        # Получаем p-значения\n",
        "        p_values = model.pvalues\n",
        "        # Находим максимальное p-значение\n",
        "        max_p_value = p_values.max()\n",
        "        # Если максимальное p-значение больше уровня значимости, удаляем соответствующий признак\n",
        "        if max_p_value > significance_level:\n",
        "            # Удаляем признак с максимальным p-значением\n",
        "            feature_to_drop = p_values.idxmax()\n",
        "            X = X.drop(columns=[feature_to_drop])\n",
        "            model = sm.OLS(y, X).fit()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n",
        "# Применение Backward Elimination\n",
        "model = backward_elimination(X_train, y_train)\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "fEXxX6iH8wRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Прогнозирование на тестовой выборке\n",
        "X_test_with_const = sm.add_constant(X_test)\n",
        "y_pred = model.predict(X_test_with_const)\n",
        "\n",
        "# Оценка модели\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score: {r2}')\n"
      ],
      "metadata": {
        "id": "axE1FXzt8x8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# Загрузка данных\n",
        "data = pd.read_csv('1.benign.csv')\n",
        "\n",
        "# Просмотр названий столбцов\n",
        "print(data.columns)\n",
        "\n",
        "# Замените 'MI_dir_L5_weight' на вашу целевую переменную\n",
        "target_variable = 'MI_dir_L5_weight'  # Пример целевой переменной\n",
        "\n",
        "# Определение целевой переменной и признаков\n",
        "X = data.drop(target_variable, axis=1)  # Удаляем целевую переменную из признаков\n",
        "y = data[target_variable]  # Определяем целевую переменную\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Функция для выполнения Backward Elimination\n",
        "def backward_elimination(X, y, significance_level=0.05):\n",
        "    X = sm.add_constant(X)  # Добавляем константу\n",
        "    model = sm.OLS(y, X).fit()  # Начальная модель\n",
        "    while True:\n",
        "        p_values = model.pvalues  # Получаем p-значения\n",
        "        max_p_value = p_values.max()  # Находим максимальное p-значение\n",
        "        if max_p_value > significance_level:  # Если оно больше уровня значимости\n",
        "            feature_to_drop = p_values.idxmax()  # Удаляем признак с максимальным p-значением\n",
        "            X = X.drop(columns=[feature_to_drop])\n",
        "            model = sm.OLS(y, X).fit()  # Обучаем модель заново\n",
        "        else:\n",
        "            break\n",
        "    return model, X.columns.drop('const')  # Возвращаем модель и оставшиеся признаки без 'const'\n",
        "\n",
        "# Применение Backward Elimination\n",
        "model, selected_features = backward_elimination(X_train, y_train)\n",
        "print(model.summary())\n",
        "\n",
        "# Убедитесь, что тестовая выборка содержит только выбранные признаки\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "X_test_with_const = sm.add_constant(X_test_selected)  # Добавляем константу только для тестовой выборки\n",
        "y_pred = model.predict(X_test_with_const)\n",
        "\n",
        "# Оценка модели\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'OLS Mean Squared Error: {mse}')\n",
        "print(f'OLS R^2 Score: {r2}')\n",
        "\n",
        "# Применение случайного леса\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train[selected_features], y_train)\n",
        "rf_pred = rf_model.predict(X_test[selected_features])\n",
        "\n",
        "# Оценка модели случайного леса\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "rf_r2 = r2_score(y_test, rf_pred)\n",
        "\n",
        "print(f'Random Forest Mean Squared Error: {rf_mse}')\n",
        "print(f'Random Forest R^2 Score: {rf_r2}')\n",
        "\n",
        "# Применение градиентного бустинга\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "gb_model.fit(X_train[selected_features], y_train)\n",
        "gb_pred = gb_model.predict(X_test[selected_features])\n",
        "\n",
        "# Оценка модели градиентного бустинга\n",
        "gb_mse = mean_squared_error(y_test, gb_pred)\n",
        "gb_r2 = r2_score(y_test, gb_pred)\n",
        "\n",
        "print(f'Gradient Boosting Mean Squared Error: {gb_mse}')\n",
        "print(f'Gradient Boosting R^2 Score: {gb_r2}')\n",
        "\n",
        "# Проверка на переобучение с помощью кросс-валидации\n",
        "rf_cv_scores = cross_val_score(rf_model, X[selected_features], y, cv=5, scoring='neg_mean_squared_error')\n",
        "print(f'Random Forest Cross-Validated MSE: {-rf_cv_scores.mean()}')\n",
        "\n",
        "gb_cv_scores = cross_val_score(gb_model, X[selected_features], y, cv=5, scoring='neg_mean_squared_error')\n",
        "print(f'Gradient Boosting Cross-Validated MSE: {-gb_cv_scores.mean()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbHNz5Hl9VEn",
        "outputId": "c718492c-9de3-41bd-94b3-23ff5db0157c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['MI_dir_L5_weight', 'MI_dir_L5_mean', 'MI_dir_L5_variance',\n",
            "       'MI_dir_L3_weight', 'MI_dir_L3_mean', 'MI_dir_L3_variance',\n",
            "       'MI_dir_L1_weight', 'MI_dir_L1_mean', 'MI_dir_L1_variance',\n",
            "       'MI_dir_L0.1_weight',\n",
            "       ...\n",
            "       'HpHp_L0.1_radius', 'HpHp_L0.1_covariance', 'HpHp_L0.1_pcc',\n",
            "       'HpHp_L0.01_weight', 'HpHp_L0.01_mean', 'HpHp_L0.01_std',\n",
            "       'HpHp_L0.01_magnitude', 'HpHp_L0.01_radius', 'HpHp_L0.01_covariance',\n",
            "       'HpHp_L0.01_pcc'],\n",
            "      dtype='object', length=115)\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:       MI_dir_L5_weight   R-squared:                       0.246\n",
            "Model:                            OLS   Adj. R-squared:                  0.246\n",
            "Method:                 Least Squares   F-statistic:                     1436.\n",
            "Date:                Mon, 25 Nov 2024   Prob (F-statistic):               0.00\n",
            "Time:                        15:41:43   Log-Likelihood:                -65459.\n",
            "No. Observations:               39638   AIC:                         1.309e+05\n",
            "Df Residuals:                   39628   BIC:                         1.310e+05\n",
            "Df Model:                           9                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=========================================================================================\n",
            "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "const                     0.0001   7.21e-06     19.863      0.000       0.000       0.000\n",
            "MI_dir_L5_mean            0.0008   1.42e-05     53.815      0.000       0.001       0.001\n",
            "MI_dir_L5_variance       -0.0005   6.92e-05     -6.585      0.000      -0.001      -0.000\n",
            "MI_dir_L3_weight       3.342e-05   5.54e-07     60.348      0.000    3.23e-05    3.45e-05\n",
            "MI_dir_L3_mean            0.0008   1.49e-05     52.043      0.000       0.001       0.001\n",
            "MI_dir_L3_variance        0.0010   9.06e-05     11.012      0.000       0.001       0.001\n",
            "MI_dir_L1_weight       3.378e-05   5.23e-07     64.620      0.000    3.28e-05    3.48e-05\n",
            "MI_dir_L1_mean            0.0008    1.4e-05     55.442      0.000       0.001       0.001\n",
            "MI_dir_L1_variance       -0.0004   3.61e-05     -9.754      0.000      -0.000      -0.000\n",
            "MI_dir_L0.1_weight     5.955e-06   2.63e-06      2.265      0.024    8.02e-07    1.11e-05\n",
            "MI_dir_L0.1_mean          0.0006   5.61e-06    102.249      0.000       0.001       0.001\n",
            "MI_dir_L0.1_variance     -0.0007   1.79e-05    -36.416      0.000      -0.001      -0.001\n",
            "MI_dir_L0.01_mean         0.0004    1.8e-05     21.604      0.000       0.000       0.000\n",
            "MI_dir_L0.01_variance     0.0006   1.66e-05     35.008      0.000       0.001       0.001\n",
            "H_L5_weight             3.27e-05   5.35e-07     61.100      0.000    3.16e-05    3.37e-05\n",
            "H_L5_mean                 0.0008   1.39e-05     54.792      0.000       0.001       0.001\n",
            "H_L5_variance            -0.0005   6.95e-05     -6.541      0.000      -0.001      -0.000\n",
            "H_L3_weight            3.323e-05   5.37e-07     61.833      0.000    3.22e-05    3.43e-05\n",
            "H_L3_mean                 0.0008   1.49e-05     52.043      0.000       0.001       0.001\n",
            "H_L3_variance             0.0010   9.06e-05     11.012      0.000       0.001       0.001\n",
            "H_L1_weight             3.38e-05   5.23e-07     64.582      0.000    3.28e-05    3.48e-05\n",
            "H_L1_mean                 0.0008   1.39e-05     55.470      0.000       0.001       0.001\n",
            "H_L1_variance            -0.0003    3.6e-05     -9.734      0.000      -0.000      -0.000\n",
            "H_L0.1_weight          6.575e-06   2.58e-06      2.547      0.011    1.52e-06    1.16e-05\n",
            "H_L0.1_mean               0.0006   5.81e-06     98.271      0.000       0.001       0.001\n",
            "H_L0.1_variance          -0.0006    1.8e-05    -35.234      0.000      -0.001      -0.001\n",
            "H_L0.01_mean              0.0004   1.85e-05     20.706      0.000       0.000       0.000\n",
            "H_L0.01_variance          0.0006   1.69e-05     35.682      0.000       0.001       0.001\n",
            "HH_L5_weight           1.258e-06   4.72e-07      2.668      0.008    3.34e-07    2.18e-06\n",
            "HH_L5_mean                0.0007   1.23e-05     60.603      0.000       0.001       0.001\n",
            "HH_L5_std             -5.977e-06   1.06e-06     -5.663      0.000   -8.05e-06   -3.91e-06\n",
            "HH_L5_magnitude           0.0007   2.42e-05     27.918      0.000       0.001       0.001\n",
            "HH_L5_radius             -0.0002   2.94e-05     -6.045      0.000      -0.000      -0.000\n",
            "HH_L5_covariance         -0.0001   2.79e-05     -5.327      0.000      -0.000   -9.39e-05\n",
            "HH_L5_pcc             -4.451e-08   4.63e-09     -9.604      0.000   -5.36e-08   -3.54e-08\n",
            "HH_L3_weight           1.182e-06   4.74e-07      2.493      0.013    2.53e-07    2.11e-06\n",
            "HH_L3_mean                0.0007   1.24e-05     60.102      0.000       0.001       0.001\n",
            "HH_L3_std             -1.495e-05   1.08e-06    -13.786      0.000   -1.71e-05   -1.28e-05\n",
            "HH_L3_magnitude           0.0007   2.36e-05     28.487      0.000       0.001       0.001\n",
            "HH_L3_covariance         -0.0004   4.22e-05    -10.241      0.000      -0.001      -0.000\n",
            "HH_L3_pcc             -4.578e-08   9.08e-09     -5.044      0.000   -6.36e-08    -2.8e-08\n",
            "HH_L1_mean                0.0007   1.23e-05     60.622      0.000       0.001       0.001\n",
            "HH_L1_std             -6.331e-05   4.22e-06    -15.019      0.000   -7.16e-05    -5.5e-05\n",
            "HH_L1_magnitude           0.0007   2.15e-05     31.422      0.000       0.001       0.001\n",
            "HH_L1_radius           8.286e-05   2.27e-05      3.649      0.000    3.84e-05       0.000\n",
            "HH_L1_covariance         -0.0010      0.000     -6.422      0.000      -0.001      -0.001\n",
            "HH_L1_pcc              8.517e-08   1.87e-08      4.556      0.000    4.85e-08    1.22e-07\n",
            "HH_L0.1_weight        -5.927e-06   9.72e-07     -6.099      0.000   -7.83e-06   -4.02e-06\n",
            "HH_L0.1_mean              0.0007   3.68e-06    189.549      0.000       0.001       0.001\n",
            "HH_L0.1_std              -0.0001   6.53e-06    -19.154      0.000      -0.000      -0.000\n",
            "HH_L0.1_magnitude         0.0007   2.38e-05     31.056      0.000       0.001       0.001\n",
            "HH_L0.1_radius            0.0001   1.26e-05     11.240      0.000       0.000       0.000\n",
            "HH_L0.1_covariance        0.0030      0.000     23.755      0.000       0.003       0.003\n",
            "HH_L0.1_pcc            1.078e-06      1e-07     10.780      0.000    8.82e-07    1.27e-06\n",
            "HH_L0.01_weight       -5.655e-05    4.9e-06    -11.547      0.000   -6.62e-05    -4.7e-05\n",
            "HH_L0.01_mean             0.0006   1.11e-05     56.256      0.000       0.001       0.001\n",
            "HH_L0.01_std             -0.0002   7.32e-06    -22.162      0.000      -0.000      -0.000\n",
            "HH_L0.01_magnitude        0.0007   2.79e-05     26.227      0.000       0.001       0.001\n",
            "HH_L0.01_radius          -0.0002   7.37e-06    -30.625      0.000      -0.000      -0.000\n",
            "HH_L0.01_covariance      -0.0021   6.43e-05    -33.131      0.000      -0.002      -0.002\n",
            "HH_L0.01_pcc          -2.289e-06   1.06e-07    -21.565      0.000    -2.5e-06   -2.08e-06\n",
            "HH_jit_L5_weight       1.258e-06   4.72e-07      2.668      0.008    3.34e-07    2.18e-06\n",
            "HH_jit_L5_mean        -1.455e-07   1.81e-08     -8.021      0.000   -1.81e-07    -1.1e-07\n",
            "HH_jit_L5_variance     1.251e-16   1.43e-17      8.772      0.000    9.72e-17    1.53e-16\n",
            "HH_jit_L3_weight       1.182e-06   4.74e-07      2.493      0.013    2.53e-07    2.11e-06\n",
            "HH_jit_L3_mean          1.62e-07   2.23e-08      7.272      0.000    1.18e-07    2.06e-07\n",
            "HH_jit_L3_variance    -1.586e-16   1.89e-17     -8.401      0.000   -1.96e-16   -1.22e-16\n",
            "HH_jit_L0.1_weight    -5.927e-06   9.72e-07     -6.099      0.000   -7.83e-06   -4.02e-06\n",
            "HH_jit_L0.1_mean      -1.202e-08   4.99e-09     -2.410      0.016   -2.18e-08   -2.24e-09\n",
            "HH_jit_L0.1_variance   2.526e-17   5.18e-18      4.878      0.000    1.51e-17    3.54e-17\n",
            "HH_jit_L0.01_weight   -5.655e-05    4.9e-06    -11.547      0.000   -6.62e-05    -4.7e-05\n",
            "HH_jit_L0.01_mean      -4.04e-09   4.38e-10     -9.217      0.000    -4.9e-09   -3.18e-09\n",
            "HpHp_L5_weight         1.337e-06   4.72e-07      2.831      0.005    4.11e-07    2.26e-06\n",
            "HpHp_L5_mean              0.0007   1.23e-05     59.087      0.000       0.001       0.001\n",
            "HpHp_L5_magnitude         0.0009   7.17e-06    123.437      0.000       0.001       0.001\n",
            "HpHp_L5_covariance       -0.0001   3.23e-05     -3.418      0.001      -0.000   -4.71e-05\n",
            "HpHp_L5_pcc           -1.817e-08   5.01e-09     -3.627      0.000    -2.8e-08   -8.35e-09\n",
            "HpHp_L3_weight          1.31e-06   4.76e-07      2.755      0.006    3.78e-07    2.24e-06\n",
            "HpHp_L3_mean              0.0007   1.23e-05     59.068      0.000       0.001       0.001\n",
            "HpHp_L3_std            5.815e-07   1.85e-07      3.144      0.002    2.19e-07    9.44e-07\n",
            "HpHp_L3_magnitude         0.0009   7.28e-06    121.312      0.000       0.001       0.001\n",
            "HpHp_L3_radius            0.0006   9.21e-05      6.798      0.000       0.000       0.001\n",
            "HpHp_L3_covariance       -0.0001   3.38e-05     -3.595      0.000      -0.000   -5.53e-05\n",
            "HpHp_L3_pcc           -1.722e-08   5.15e-09     -3.346      0.001   -2.73e-08   -7.13e-09\n",
            "HpHp_L1_weight         1.271e-06   4.83e-07      2.630      0.009    3.24e-07    2.22e-06\n",
            "HpHp_L1_mean              0.0007   1.22e-05     59.529      0.000       0.001       0.001\n",
            "HpHp_L1_std           -7.815e-07   3.13e-07     -2.497      0.013   -1.39e-06   -1.68e-07\n",
            "HpHp_L1_magnitude         0.0009   7.51e-06    117.608      0.000       0.001       0.001\n",
            "HpHp_L1_radius          3.64e-05   1.15e-05      3.176      0.001    1.39e-05    5.89e-05\n",
            "HpHp_L1_covariance        0.0001   4.85e-05      2.705      0.007    3.61e-05       0.000\n",
            "HpHp_L1_pcc            3.212e-08   8.07e-09      3.981      0.000    1.63e-08    4.79e-08\n",
            "HpHp_L0.1_mean            0.0007   1.19e-05     60.712      0.000       0.001       0.001\n",
            "HpHp_L0.1_std          1.683e-06   3.51e-07      4.798      0.000    9.95e-07    2.37e-06\n",
            "HpHp_L0.1_magnitude       0.0009   7.51e-06    117.604      0.000       0.001       0.001\n",
            "HpHp_L0.1_radius         -0.0003   3.69e-05     -8.962      0.000      -0.000      -0.000\n",
            "HpHp_L0.1_covariance      0.0002   7.14e-05      3.227      0.001    9.05e-05       0.000\n",
            "HpHp_L0.1_pcc          5.288e-08   1.12e-08      4.715      0.000    3.09e-08    7.49e-08\n",
            "HpHp_L0.01_weight     -1.443e-05   3.32e-06     -4.351      0.000   -2.09e-05   -7.93e-06\n",
            "HpHp_L0.01_mean           0.0007   1.16e-05     61.948      0.000       0.001       0.001\n",
            "HpHp_L0.01_std         3.094e-06   4.97e-07      6.224      0.000    2.12e-06    4.07e-06\n",
            "HpHp_L0.01_magnitude      0.0009   6.57e-06    131.081      0.000       0.001       0.001\n",
            "HpHp_L0.01_radius        -0.0003   3.72e-05     -8.754      0.000      -0.000      -0.000\n",
            "HpHp_L0.01_covariance     0.0002   7.34e-05      2.929      0.003    7.11e-05       0.000\n",
            "==============================================================================\n",
            "Omnibus:                     4135.506   Durbin-Watson:                   2.002\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6704.605\n",
            "Skew:                           0.753   Prob(JB):                         0.00\n",
            "Kurtosis:                       4.338   Cond. No.                     2.58e+16\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.58e+16. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "OLS Mean Squared Error: 1.6511636768348676\n",
            "OLS R^2 Score: 0.2192993474873004\n",
            "Random Forest Mean Squared Error: 4.661020128864045e-06\n",
            "Random Forest R^2 Score: 0.9999977961836812\n",
            "Gradient Boosting Mean Squared Error: 1.957530720573545e-05\n",
            "Gradient Boosting R^2 Score: 0.9999907444335634\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d305d016b184>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Проверка на переобучение с помощью кросс-валидации\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mrf_cv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Random Forest Cross-Validated MSE: {-rf_cv_scores.mean()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    424\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         tree._fit(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n"
      ],
      "metadata": {
        "id": "6z3mWa499XFI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "data = pd.read_csv('1.benign.csv')\n",
        "\n",
        "# Просмотр названий столбцов\n",
        "print(data.columns)\n",
        "\n",
        "# Замените 'MI_dir_L5_weight' на вашу целевую переменную\n",
        "target_variable = 'MI_dir_L5_weight'  # Пример целевой переменной\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzHMTX44Dj4W",
        "outputId": "b1981fc0-4ec1-471b-9752-0e86c41aa654"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['MI_dir_L5_weight', 'MI_dir_L5_mean', 'MI_dir_L5_variance',\n",
            "       'MI_dir_L3_weight', 'MI_dir_L3_mean', 'MI_dir_L3_variance',\n",
            "       'MI_dir_L1_weight', 'MI_dir_L1_mean', 'MI_dir_L1_variance',\n",
            "       'MI_dir_L0.1_weight',\n",
            "       ...\n",
            "       'HpHp_L0.1_radius', 'HpHp_L0.1_covariance', 'HpHp_L0.1_pcc',\n",
            "       'HpHp_L0.01_weight', 'HpHp_L0.01_mean', 'HpHp_L0.01_std',\n",
            "       'HpHp_L0.01_magnitude', 'HpHp_L0.01_radius', 'HpHp_L0.01_covariance',\n",
            "       'HpHp_L0.01_pcc'],\n",
            "      dtype='object', length=115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение целевой переменной и признаков\n",
        "X = data.drop(target_variable, axis=1)  # Удаляем целевую переменную из признаков\n",
        "y = data[target_variable]  # Определяем целевую переменную\n"
      ],
      "metadata": {
        "id": "MqTDLEXYDlJt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Y3Bb_Pg4Dpkh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для выполнения Backward Elimination\n",
        "def backward_elimination(X, y, significance_level=0.05):\n",
        "    X = sm.add_constant(X)  # Добавляем константу\n",
        "    model = sm.OLS(y, X).fit()  # Начальная модель\n",
        "    while True:\n",
        "        p_values = model.pvalues  # Получаем p-значения\n",
        "        max_p_value = p_values.max()  # Находим максимальное p-значение\n",
        "        if max_p_value > significance_level:  # Если оно больше уровня значимости\n",
        "            feature_to_drop = p_values.idxmax()  # Удаляем признак с максимальным p-значением\n",
        "            X = X.drop(columns=[feature_to_drop])\n",
        "            model = sm.OLS(y, X).fit()  # Обучаем модель заново\n",
        "        else:\n",
        "            break\n",
        "    return model, X.columns.drop('const')  # Возвращаем модель и оставшиеся признаки без 'const'\n"
      ],
      "metadata": {
        "id": "N8_pqJHpDp_E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Применение Backward Elimination\n",
        "model, selected_features = backward_elimination(X_train, y_train)\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA1s0RYRDsjl",
        "outputId": "628e19dc-95ca-4cab-8747-f0181939b214"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:       MI_dir_L5_weight   R-squared:                       0.246\n",
            "Model:                            OLS   Adj. R-squared:                  0.246\n",
            "Method:                 Least Squares   F-statistic:                     1436.\n",
            "Date:                Mon, 25 Nov 2024   Prob (F-statistic):               0.00\n",
            "Time:                        16:02:21   Log-Likelihood:                -65459.\n",
            "No. Observations:               39638   AIC:                         1.309e+05\n",
            "Df Residuals:                   39628   BIC:                         1.310e+05\n",
            "Df Model:                           9                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=========================================================================================\n",
            "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "const                     0.0001   7.21e-06     19.863      0.000       0.000       0.000\n",
            "MI_dir_L5_mean            0.0008   1.42e-05     53.815      0.000       0.001       0.001\n",
            "MI_dir_L5_variance       -0.0005   6.92e-05     -6.585      0.000      -0.001      -0.000\n",
            "MI_dir_L3_weight       3.342e-05   5.54e-07     60.348      0.000    3.23e-05    3.45e-05\n",
            "MI_dir_L3_mean            0.0008   1.49e-05     52.043      0.000       0.001       0.001\n",
            "MI_dir_L3_variance        0.0010   9.06e-05     11.012      0.000       0.001       0.001\n",
            "MI_dir_L1_weight       3.378e-05   5.23e-07     64.620      0.000    3.28e-05    3.48e-05\n",
            "MI_dir_L1_mean            0.0008    1.4e-05     55.442      0.000       0.001       0.001\n",
            "MI_dir_L1_variance       -0.0004   3.61e-05     -9.754      0.000      -0.000      -0.000\n",
            "MI_dir_L0.1_weight     5.955e-06   2.63e-06      2.265      0.024    8.02e-07    1.11e-05\n",
            "MI_dir_L0.1_mean          0.0006   5.61e-06    102.249      0.000       0.001       0.001\n",
            "MI_dir_L0.1_variance     -0.0007   1.79e-05    -36.416      0.000      -0.001      -0.001\n",
            "MI_dir_L0.01_mean         0.0004    1.8e-05     21.604      0.000       0.000       0.000\n",
            "MI_dir_L0.01_variance     0.0006   1.66e-05     35.008      0.000       0.001       0.001\n",
            "H_L5_weight             3.27e-05   5.35e-07     61.100      0.000    3.16e-05    3.37e-05\n",
            "H_L5_mean                 0.0008   1.39e-05     54.792      0.000       0.001       0.001\n",
            "H_L5_variance            -0.0005   6.95e-05     -6.541      0.000      -0.001      -0.000\n",
            "H_L3_weight            3.323e-05   5.37e-07     61.833      0.000    3.22e-05    3.43e-05\n",
            "H_L3_mean                 0.0008   1.49e-05     52.043      0.000       0.001       0.001\n",
            "H_L3_variance             0.0010   9.06e-05     11.012      0.000       0.001       0.001\n",
            "H_L1_weight             3.38e-05   5.23e-07     64.582      0.000    3.28e-05    3.48e-05\n",
            "H_L1_mean                 0.0008   1.39e-05     55.470      0.000       0.001       0.001\n",
            "H_L1_variance            -0.0003    3.6e-05     -9.734      0.000      -0.000      -0.000\n",
            "H_L0.1_weight          6.575e-06   2.58e-06      2.547      0.011    1.52e-06    1.16e-05\n",
            "H_L0.1_mean               0.0006   5.81e-06     98.271      0.000       0.001       0.001\n",
            "H_L0.1_variance          -0.0006    1.8e-05    -35.234      0.000      -0.001      -0.001\n",
            "H_L0.01_mean              0.0004   1.85e-05     20.706      0.000       0.000       0.000\n",
            "H_L0.01_variance          0.0006   1.69e-05     35.682      0.000       0.001       0.001\n",
            "HH_L5_weight           1.258e-06   4.72e-07      2.668      0.008    3.34e-07    2.18e-06\n",
            "HH_L5_mean                0.0007   1.23e-05     60.603      0.000       0.001       0.001\n",
            "HH_L5_std             -5.977e-06   1.06e-06     -5.663      0.000   -8.05e-06   -3.91e-06\n",
            "HH_L5_magnitude           0.0007   2.42e-05     27.918      0.000       0.001       0.001\n",
            "HH_L5_radius             -0.0002   2.94e-05     -6.045      0.000      -0.000      -0.000\n",
            "HH_L5_covariance         -0.0001   2.79e-05     -5.327      0.000      -0.000   -9.39e-05\n",
            "HH_L5_pcc             -4.451e-08   4.63e-09     -9.604      0.000   -5.36e-08   -3.54e-08\n",
            "HH_L3_weight           1.182e-06   4.74e-07      2.493      0.013    2.53e-07    2.11e-06\n",
            "HH_L3_mean                0.0007   1.24e-05     60.102      0.000       0.001       0.001\n",
            "HH_L3_std             -1.495e-05   1.08e-06    -13.786      0.000   -1.71e-05   -1.28e-05\n",
            "HH_L3_magnitude           0.0007   2.36e-05     28.487      0.000       0.001       0.001\n",
            "HH_L3_covariance         -0.0004   4.22e-05    -10.241      0.000      -0.001      -0.000\n",
            "HH_L3_pcc             -4.578e-08   9.08e-09     -5.044      0.000   -6.36e-08    -2.8e-08\n",
            "HH_L1_mean                0.0007   1.23e-05     60.622      0.000       0.001       0.001\n",
            "HH_L1_std             -6.331e-05   4.22e-06    -15.019      0.000   -7.16e-05    -5.5e-05\n",
            "HH_L1_magnitude           0.0007   2.15e-05     31.422      0.000       0.001       0.001\n",
            "HH_L1_radius           8.286e-05   2.27e-05      3.649      0.000    3.84e-05       0.000\n",
            "HH_L1_covariance         -0.0010      0.000     -6.422      0.000      -0.001      -0.001\n",
            "HH_L1_pcc              8.517e-08   1.87e-08      4.556      0.000    4.85e-08    1.22e-07\n",
            "HH_L0.1_weight        -5.927e-06   9.72e-07     -6.099      0.000   -7.83e-06   -4.02e-06\n",
            "HH_L0.1_mean              0.0007   3.68e-06    189.549      0.000       0.001       0.001\n",
            "HH_L0.1_std              -0.0001   6.53e-06    -19.154      0.000      -0.000      -0.000\n",
            "HH_L0.1_magnitude         0.0007   2.38e-05     31.056      0.000       0.001       0.001\n",
            "HH_L0.1_radius            0.0001   1.26e-05     11.240      0.000       0.000       0.000\n",
            "HH_L0.1_covariance        0.0030      0.000     23.755      0.000       0.003       0.003\n",
            "HH_L0.1_pcc            1.078e-06      1e-07     10.780      0.000    8.82e-07    1.27e-06\n",
            "HH_L0.01_weight       -5.655e-05    4.9e-06    -11.547      0.000   -6.62e-05    -4.7e-05\n",
            "HH_L0.01_mean             0.0006   1.11e-05     56.256      0.000       0.001       0.001\n",
            "HH_L0.01_std             -0.0002   7.32e-06    -22.162      0.000      -0.000      -0.000\n",
            "HH_L0.01_magnitude        0.0007   2.79e-05     26.227      0.000       0.001       0.001\n",
            "HH_L0.01_radius          -0.0002   7.37e-06    -30.625      0.000      -0.000      -0.000\n",
            "HH_L0.01_covariance      -0.0021   6.43e-05    -33.131      0.000      -0.002      -0.002\n",
            "HH_L0.01_pcc          -2.289e-06   1.06e-07    -21.565      0.000    -2.5e-06   -2.08e-06\n",
            "HH_jit_L5_weight       1.258e-06   4.72e-07      2.668      0.008    3.34e-07    2.18e-06\n",
            "HH_jit_L5_mean        -1.455e-07   1.81e-08     -8.021      0.000   -1.81e-07    -1.1e-07\n",
            "HH_jit_L5_variance     1.251e-16   1.43e-17      8.772      0.000    9.72e-17    1.53e-16\n",
            "HH_jit_L3_weight       1.182e-06   4.74e-07      2.493      0.013    2.53e-07    2.11e-06\n",
            "HH_jit_L3_mean          1.62e-07   2.23e-08      7.272      0.000    1.18e-07    2.06e-07\n",
            "HH_jit_L3_variance    -1.586e-16   1.89e-17     -8.401      0.000   -1.96e-16   -1.22e-16\n",
            "HH_jit_L0.1_weight    -5.927e-06   9.72e-07     -6.099      0.000   -7.83e-06   -4.02e-06\n",
            "HH_jit_L0.1_mean      -1.202e-08   4.99e-09     -2.410      0.016   -2.18e-08   -2.24e-09\n",
            "HH_jit_L0.1_variance   2.526e-17   5.18e-18      4.878      0.000    1.51e-17    3.54e-17\n",
            "HH_jit_L0.01_weight   -5.655e-05    4.9e-06    -11.547      0.000   -6.62e-05    -4.7e-05\n",
            "HH_jit_L0.01_mean      -4.04e-09   4.38e-10     -9.217      0.000    -4.9e-09   -3.18e-09\n",
            "HpHp_L5_weight         1.337e-06   4.72e-07      2.831      0.005    4.11e-07    2.26e-06\n",
            "HpHp_L5_mean              0.0007   1.23e-05     59.087      0.000       0.001       0.001\n",
            "HpHp_L5_magnitude         0.0009   7.17e-06    123.437      0.000       0.001       0.001\n",
            "HpHp_L5_covariance       -0.0001   3.23e-05     -3.418      0.001      -0.000   -4.71e-05\n",
            "HpHp_L5_pcc           -1.817e-08   5.01e-09     -3.627      0.000    -2.8e-08   -8.35e-09\n",
            "HpHp_L3_weight          1.31e-06   4.76e-07      2.755      0.006    3.78e-07    2.24e-06\n",
            "HpHp_L3_mean              0.0007   1.23e-05     59.068      0.000       0.001       0.001\n",
            "HpHp_L3_std            5.815e-07   1.85e-07      3.144      0.002    2.19e-07    9.44e-07\n",
            "HpHp_L3_magnitude         0.0009   7.28e-06    121.312      0.000       0.001       0.001\n",
            "HpHp_L3_radius            0.0006   9.21e-05      6.798      0.000       0.000       0.001\n",
            "HpHp_L3_covariance       -0.0001   3.38e-05     -3.595      0.000      -0.000   -5.53e-05\n",
            "HpHp_L3_pcc           -1.722e-08   5.15e-09     -3.346      0.001   -2.73e-08   -7.13e-09\n",
            "HpHp_L1_weight         1.271e-06   4.83e-07      2.630      0.009    3.24e-07    2.22e-06\n",
            "HpHp_L1_mean              0.0007   1.22e-05     59.529      0.000       0.001       0.001\n",
            "HpHp_L1_std           -7.815e-07   3.13e-07     -2.497      0.013   -1.39e-06   -1.68e-07\n",
            "HpHp_L1_magnitude         0.0009   7.51e-06    117.608      0.000       0.001       0.001\n",
            "HpHp_L1_radius          3.64e-05   1.15e-05      3.176      0.001    1.39e-05    5.89e-05\n",
            "HpHp_L1_covariance        0.0001   4.85e-05      2.705      0.007    3.61e-05       0.000\n",
            "HpHp_L1_pcc            3.212e-08   8.07e-09      3.981      0.000    1.63e-08    4.79e-08\n",
            "HpHp_L0.1_mean            0.0007   1.19e-05     60.712      0.000       0.001       0.001\n",
            "HpHp_L0.1_std          1.683e-06   3.51e-07      4.798      0.000    9.95e-07    2.37e-06\n",
            "HpHp_L0.1_magnitude       0.0009   7.51e-06    117.604      0.000       0.001       0.001\n",
            "HpHp_L0.1_radius         -0.0003   3.69e-05     -8.962      0.000      -0.000      -0.000\n",
            "HpHp_L0.1_covariance      0.0002   7.14e-05      3.227      0.001    9.05e-05       0.000\n",
            "HpHp_L0.1_pcc          5.288e-08   1.12e-08      4.715      0.000    3.09e-08    7.49e-08\n",
            "HpHp_L0.01_weight     -1.443e-05   3.32e-06     -4.351      0.000   -2.09e-05   -7.93e-06\n",
            "HpHp_L0.01_mean           0.0007   1.16e-05     61.948      0.000       0.001       0.001\n",
            "HpHp_L0.01_std         3.094e-06   4.97e-07      6.224      0.000    2.12e-06    4.07e-06\n",
            "HpHp_L0.01_magnitude      0.0009   6.57e-06    131.081      0.000       0.001       0.001\n",
            "HpHp_L0.01_radius        -0.0003   3.72e-05     -8.754      0.000      -0.000      -0.000\n",
            "HpHp_L0.01_covariance     0.0002   7.34e-05      2.929      0.003    7.11e-05       0.000\n",
            "==============================================================================\n",
            "Omnibus:                     4135.506   Durbin-Watson:                   2.002\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6704.605\n",
            "Skew:                           0.753   Prob(JB):                         0.00\n",
            "Kurtosis:                       4.338   Cond. No.                     2.58e+16\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.58e+16. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Убедитесь, что тестовая выборка содержит только выбранные признаки\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "X_test_with_const = sm.add_constant(X_test_selected)  # Добавляем константу только для тестовой выборки\n",
        "y_pred = model.predict(X_test_with_const)\n",
        "\n",
        "# Оценка модели\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'OLS Mean Squared Error: {mse}')\n",
        "print(f'OLS R^2 Score: {r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx5XF-CfDuPl",
        "outputId": "0dfdbce8-c804-41e0-cba8-33832dabc2b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLS Mean Squared Error: 1.6511636768348676\n",
            "OLS R^2 Score: 0.2192993474873004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Применение случайного леса\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train[selected_features], y_train)\n",
        "rf_pred = rf_model.predict(X_test[selected_features])\n",
        "\n",
        "# Оценка модели случайного леса\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "rf_r2 = r2_score(y_test, rf_pred)\n",
        "\n",
        "print(f'Random Forest Mean Squared Error: {rf_mse}')\n",
        "print(f'Random Forest R^2 Score: {rf_r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfEkOHUKDytr",
        "outputId": "4b430b71-1d8f-43ca-8cdd-797901dfea6e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Mean Squared Error: 4.661020128864045e-06\n",
            "Random Forest R^2 Score: 0.9999977961836812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на обучающую и валидационную выборки\n",
        "X_train_holdout, X_val, y_train_holdout, y_val = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучение модели случайного леса\n",
        "rf_model_holdout = RandomForestRegressor(random_state=42)\n",
        "rf_model_holdout.fit(X_train_holdout, y_train_holdout)\n",
        "\n",
        "# Оценка на валидационной выборке\n",
        "rf_val_pred = rf_model_holdout.predict(X_val)\n",
        "rf_val_mse = mean_squared_error(y_val, rf_val_pred)\n",
        "\n",
        "print(f'Random Forest Holdout MSE: {rf_val_mse}')\n",
        "\n",
        "# Обучение модели градиентного бустинга\n",
        "gb_model_holdout = GradientBoostingRegressor(random_state=42)\n",
        "gb_model_holdout.fit(X_train_holdout, y_train_holdout)\n",
        "\n",
        "# Оценка на валидационной выборке\n",
        "gb_val_pred = gb_model_holdout.predict(X_val)\n",
        "gb_val_mse = mean_squared_error(y_val, gb_val_pred)\n",
        "\n",
        "print(f'Gradient Boosting Holdout MSE: {gb_val_mse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "2oQ0f0V2D2qV",
        "outputId": "ab65cdfa-da92-46f3-84c5-e1c0db308243"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bc1e56434803>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Обучение модели случайного леса\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrf_model_holdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrf_model_holdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_holdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_holdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Оценка на валидационной выборке\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         tree._fit(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка на переобучение с помощью кросс-валидации с меньшим числом фолдов\n",
        "rf_cv_scores = cross_val_score(rf_model, X[selected_features], y, cv=3, scoring='neg_mean_squared_error')\n",
        "print(f'Random Forest Cross-Validated MSE (3 folds): {-rf_cv_scores.mean()}')\n",
        "\n",
        "gb_cv_scores = cross_val_score(gb_model, X[selected_features], y, cv=3, scoring='neg_mean_squared_error')\n",
        "print(f'Gradient Boosting Cross-Validated MSE (3 folds): {-gb_cv_scores.mean()}')\n"
      ],
      "metadata": {
        "id": "hFhxlFg7FLKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Повторное использование train_test_split для оценки\n",
        "num_iterations = 5\n",
        "rf_mse_scores = []\n",
        "gb_mse_scores = []\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X[selected_features], y, test_size=0.2, random_state=None)\n",
        "\n",
        "    # Оценка модели случайного леса\n",
        "    rf_model_split = RandomForestRegressor(random_state=42)\n",
        "    rf_model_split.fit(X_train_split, y_train_split)\n",
        "    rf_val_pred = rf_model_split.predict(X_val_split)\n",
        "    rf_mse_scores.append(mean_squared_error(y_val_split, rf_val_pred))\n",
        "\n",
        "    # Оценка модели градиентного бустинга\n",
        "    gb_model_split = GradientBoostingRegressor(random_state=42)\n",
        "    gb_model_split.fit(X_train_split, y_train_split)\n",
        "    gb_val_pred = gb_model_split.predict(X_val_split)\n",
        "    gb_mse_scores.append(mean_squared_error(y_val_split, gb_val_pred))\n",
        "\n",
        "print(f'Random Forest Average MSE over {num_iterations} iterations: {np.mean(rf_mse_scores)}')\n",
        "print(f'Gradient Boosting Average MSE over {num_iterations} iterations: {np.mean(gb_mse_scores)}')\n"
      ],
      "metadata": {
        "id": "Zozld7M6FNXU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}