{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4sY6vP9F4VYBYtM4knrs4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Цели и задачи\n","\n","Цель лабораторной работы: изучение принципов построения информационных систем с использованием линейных методов машинного обучения.\n","Основные задачи:\n","–\tосвоение методологии работы с моделями линейной регресии в задачах машинного обучения;\n","–\tосвоение метдик работы с линейными моделями в python;\n","–\tосвоение методики применения методов регрессии;\n","–\tизучение основных параметров регрессионных моделей.\n","Оборудование и материалы\n","\n","Для выполнения лабораторной работы рекомендуется использовать персональный компьютер со следующими программными средствами разработки (выбрать один или несколько програмных продуктов для практической реализации задач лабораторной работы): MS Visual Studio 2013 и выше; среда разработки Java, интерпретатор Python (Jupyter Notebook).\n","\n","Методика и порядок выполнения работы\n","\n","Постановка задачи.\n","В рамках учебной задачи резберем проблему «Прогноз популярности статьи на Хабре» (https://habrahabr.ru). Подробности\n","(https://inclass.kaggle.com/c/howpop-habrahabr-favs).\n","Файл howpop_test.csv содержит тестовые объекты. Файл howpop_train.csv содержит обучающую выборку. Целевая переменная – favs_lognorm. Файлы howpop_test.jsonlines и howpop_train.jsonlines содержат полные описания статей в формате JSON. Целевая переменная – favs_lognorm.\n","Следует обратить внимание, что howpop_train.jsonlines – файл с размером 4 ГБ.  \n","Переходим к решению:\n","17.\tПодключем необходимые библиотеки:\n"],"metadata":{"id":"x6TIVTGj-qGJ"}},{"cell_type":"code","source":["from __future__ import division, print_function\n","import numpy as np\n","import pandas as pd\n","import scipy\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Ridge"],"metadata":{"id":"kEUDwUpx-rOv","executionInfo":{"status":"ok","timestamp":1725553266331,"user_tz":-180,"elapsed":2300,"user":{"displayName":"Рахно Михаил ВИС32","userId":"05638063217823062993"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["18.\tПроведем первичное обследование набора данных. Выполним загрузку данных (рис. 6.2). Такое представление обучающей и тестовой выборок не дает осмысленного представления о структуре данных, вывод тяжело читается. Трансформируем вывод следующим образом (рис. 6.3): в методе head() будем выводить одну строку, а также транспонируем вывод."],"metadata":{"id":"aJBeYdIy-5Jo"}},{"cell_type":"code","source":["train_df = pd.read_csv('dataset/how pop_train.csv')\n","test_df = pd.read_csv('dataset/how pop_test.csv')\n","print('//////////////////')\n","print(train_df.head())\n","print('//////////////////')\n","print(test_df.head())"],"metadata":{"id":"I9thR8ZA-53B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('dataset/how pop_train.csv')\n","test_df = pd.read_csv('dataset/how pop_test.csv')\n","print('|||||||||||||||||||||||||||||||||||||||||||||')\n","print(train_df.head(1).T)\n","print('|||||||||||||||||||||||||||||||||||||||||||||')\n","print(test_df.head(1).T)"],"metadata":{"id":"02GYVHQzACdA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["19.\tОпределим размер выборок"],"metadata":{"id":"Pp45etZnAM8k"}},{"cell_type":"code","source":["print('Тестовый набор: \\t', test_df.shape)\n","print('Обучающая выборка: \\t', train_df.shape)"],"metadata":{"id":"8UeKmROxANf4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["20.\tПолучим общую информацию по фрейму:"],"metadata":{"id":"MN8Hc2mUASMy"}},{"cell_type":"code","source":["print( train_df.info ())"],"metadata":{"id":"a260r_04ATn1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["21.\tРассмотрим, каким образом упорядочены данные в train_df по временной оси (по published). Для этого используем код (рис. 6.7). Данные упорядочены по полю published"],"metadata":{"id":"v3aPEjVGAZlk"}},{"cell_type":"code","source":["#копируем столбец данных published\n","ser_data = train_df['published'].apply(lambda ts: pd.to_datetime(ts))\n","print('Ряд с датами столбца published')\n","print(ser_data.head())\n","print('Размер объекта Series: ', df1.shape)\n","ser_data.apply(lambda el: el.value).plot()"],"metadata":{"id":"d5Kws0PnAbTZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["22.\tПродолжим анализировать набор данных и определим, существует ли корреляция между отдельными признаками. Для этого воспользуемся методом pandas.DataFrame.corr(). Вызвав реализацию функции по умолчанию train_df.corr(), получим коэффициенты корреляции."],"metadata":{"id":"M7cA-4gCA28X"}},{"cell_type":"code","source":["corr = train_df.corr()\n","corr"],"metadata":{"id":"ero8jB54A9bI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["По данной матрице необходимо определить коррелирующие рпизнаки (с коэффициентом корреляции больше 0.9). Искать такие значения по представленной матрице – достаточно сложная задача, которая повлечет ошибки, поэтому представим матрицу корреляции в удобном для анализа виде:"],"metadata":{"id":"0s_yZWjUBHXY"}},{"cell_type":"code","source":["corr[corr>0.9].replace({np.nan : ''})"],"metadata":{"id":"K1H3QSQvBLFM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Таким образом устанавливаем, что признаки набора данных независимы."],"metadata":{"id":"mzMG8HbZBRa-"}},{"cell_type":"markdown","source":["23.\tПроведем еще одно исследование: определим как распределены публикации по годам"],"metadata":{"id":"ZJ-6vxamBS4O"}},{"cell_type":"code","source":["df = train_df.copy()\n","df['published'] = pd.to_datetime(df['published']).dt.year\n","ss = df['published'].value_counts()\n","print(ss.sort_index())"],"metadata":{"id":"n0zrsK-rBVXs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["24.\tПервичное исследование набора данных завершено. Перейдем непосредственно к построению модели обучения. Разделим исходный набор данных на тренировочную и тестовую подвыборки, а также отберем признаки, которые будут использоваться в процессе обучения."],"metadata":{"id":"WkOKN8xMBgUZ"}},{"cell_type":"code","source":["features = ['author', 'flow', 'domain','title']\n","train_size = int(0.7 * train_df.shape[0])\n","print('Размер исходного набора: ', len(train_df),\n","      '\\nРазмер обучающей подвыборки: ', train_size)\n","\n","#отделяем признаки от целевой переменной\n","X, y = train_df.ix[:, features], train_df['favs_lognorm']\n","X_test = test_df.ix[:, features]\n","X_train, X_valid = X.iloc[:train_size, :], X.iloc[train_size:,:]\n","y_train, y_valid = y.iloc[:train_size], y.iloc[train_size:]"],"metadata":{"id":"mk03V9TkBhV4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["25.\tДля анализа контента (содержимого файлов howpop_*.jsonlines) тспользуем TfidfVectorizer из пакета sklearn. TF-IDF (от англ. TF – term frequency, IDF – inverse document frequency) – статистическая мера, используемая для оценки важности слова в контексте документа, являющегося частью коллекции документов или корпуса. Вес некоторого слова пропорционален количеству употребления этого слова в документе, и обратно пропорционален частоте употребления слова в других документах коллекции.\n","TfidfVectorizer преобразует тексты в матрицу TF-IDF признаков.\n","Основные параметры TfidfVectorizer в sklearn:\n","–\tmin_df – при построении словаря слова, которые встречаются реже, чем указанное значение, игнорируются;\n","–\tmax_df – при построении словаря слова, которые встречаются чаще, чем указанное значение, игнорируются;\n","–\tanalyzer – определяет, строятся ли признаки по словам или по символам (буквам);\n","–\tngram_range – определяет, формируются ли признаки только из отдельных слов или из нескольких слов (в случае с analyzer='char' задает количество символов). Например, если указать analyzer='word' и ngram_range=(1,3),то признаки будут формироваться из отдельных слов, из пар слов и из троек слов;\n","–\tstop_words – слова, которые игнорируются при построении матрицы.\n","Создадим объект TfidfVectorizer и обучим его на данных\n"],"metadata":{"id":"ubLarxUpBvRC"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer_title = TfidfVectorizer(min_df=3, max_df=0.3, ngram_range=(1,3))\n","vX_train_title = vectorizer_title.fit(X_train['title'])\n","print('vX_train_title.vocabulary_:', len(vX_train_title.vocabulary_))\n","vX_valid_title = vectorizer_title.fit(X_valid['title'])\n","print('vX_train_title.vocabulary_:', len(vX_train_title.vocabulary_))\n","vX_test_title = vectorizer_title.fit(X_test['title'])\n","\n","print('vX_train_title.vocabulary_:', len(vX_train_title.vocabulary_))\n","X_train_title = vectorizer_title.fit_transform(X_train['title'])\n","print('X_train_title.shape: ', X_train_title.shape)\n","X_valid_title = vectorizer_title.transform(X_valid['title'])\n","print('X_valid_title.shape: ', X_valid_title.shape)\n","X_test_title = vectorizer_title.transform(X_test['title'])\n","print('X_test_title.shape: ', X_test_title.shape)"],"metadata":{"id":"pxduDsN6B1bP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Получили три словаря и три матрицы TF-IDF. Для доступа к словарям можно обратиться к полю vocabulary_ объекта TfidfVectorizer. К этому времени объект должен быть обучен – должен быть вызван метод\n","fit_transform().\n"],"metadata":{"id":"BKNl_2Y0CAPb"}},{"cell_type":"code","source":["X_test_title.vocabulary_"],"metadata":{"id":"hQ9oI_dsCFvr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Данные в словаре хранятся в формате {'термин': индекс признака,...}."],"metadata":{"id":"3NyOr2aECSpA"}},{"cell_type":"markdown","source":["26.\tПостроим TF-IDF-матрицы для этих же признаков, но с использованием параметра analyzer='char'"],"metadata":{"id":"pz0OEfUACUjO"}},{"cell_type":"code","source":["vectorizer_title_ch = TfidfVectorizer(analyzer='char')\n","\n","vX_train_title_ch = vectorizer_title_ch.fit(X_train['title'])\n","print('vX_train_title_ch.vocabulary_:', len(vX_train_title_ch.vocabulary_))\n","vX_valid_title_ch = vectorizer_title_ch.fit(X_valid['title'])\n","print('vX_valid_title_ch.vocabulary_: ', len(vX_valid_title_ch.vocabulary_))\n","vX_test_title_ch = vectorizer_title_ch.fit(X_test['title'])\n","print('vX_test_title_ch.vocabulary_:', len(vX_test_title_ch.vocabulary_))\n","\n","X_train_title_ch = vectorizer_title_ch.fit_transform(X_train['title'])\n","print('X_train_title_ch.shape: ', X_train_title_ch.shape)\n","X_valid_title_ch = vectorizer_title_ch.transform(X_valid['title'])\n","print('X_valid_title_ch.shape: ', X_valid_title_ch.shape)\n","X_test_title_ch = vectorizer_title_ch.transform(X_test['title'])\n","print('X_test_title_ch.shape: ', X_test_title_ch.shape)"],"metadata":{"id":"X_szWkL2CWMM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["27.\tДля \tобработки \tостальных \tпризнаков \tбудем \tиспользовать DictVectorizer из sklearn. Признаки ['author', 'flow', 'domain'] имеют категориальную природу, для них TfidfVectorizer неприменим."],"metadata":{"id":"nEvZtxlpCltP"}},{"cell_type":"code","source":["vectorizer_feats = DictVectorizer()\n","tmp_dict_train = X_train[feats].fillna('-').T.to_dict().values()\n","tmp_dict_valid = X_valid[feats].fillna('-').T.to_dict().values()\n","tmp_dict_test = X_test[feats].fillna('-').T.to_dict().values()\n","\n","X_train_feats = vectorizer_feats.fit_transform(tmp_dict_train)\n","X_valid_feats = vectorizer_feats.transform(tmp_dict_valid)\n","X_test_feats = vectorizer_feats.transform(tmp_dict_test)\n","print(X_train_feats.shape)\n","print(X_valid_feats.shape)\n","print(X_test_feats.shape)"],"metadata":{"id":"Omrg6nS_Cn3D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["28.\tВыполним объединение полученных матриц"],"metadata":{"id":"om2bIP-UC1uw"}},{"cell_type":"code","source":["#объединение матриц, построенных на предыдущих этапах\n","X_train_new = scipy.sparse.hstack([X_train_title,\n","                                  X_train_feats,\n","                                  X_train_title_ch])\n","X_valid_new = scipy.sparse.hstack([X_valid_title,\n","                                  X_valid_feats,\n","                                  X_valid_title_ch])\n","X_test_new = scipy.sparse.hstack([X_test_title,\n","                                  X_test_feats,\n","                                  X_test_title_ch])\n","print(X_train_new.shape)\n","print(X_valid_new.shape)\n","print(X_test_new.shape)"],"metadata":{"id":"ysIUj7MTC3Nl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Следует обратить внимание, что операция объединения допустима над полученными матрицами (поясните почему)."],"metadata":{"id":"TmPH0xWEDNjp"}},{"cell_type":"markdown","source":["29.\tДля обучения выбрана линейная модель регрессии с L2регуляризацией"],"metadata":{"id":"Cgtxb7cYDOYB"}},{"cell_type":"code","source":["%%time\n","model_1 = Ridge(alpha=.1, random_state=1)\n","model_1.fit(X_train_new, y_train)"],"metadata":{"id":"hfg71ObMDPzY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_press1 = model_1.predict(X_train_new)\n","valid_predc1 = model_1.product(X_valid_new)\n","print('Ошибка на трейне: ', mean_squared_error(y_train, train_press1))\n","print('Ошибка на тесте: ', mean_squared_error(y_valid, valid_predc1))"],"metadata":{"id":"Bo5Vmm_iDXGi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["30.\tВыполним обучение еще одной модели и проверим ошибки"],"metadata":{"id":"iBxkiDJ_DqTx"}},{"cell_type":"code","source":["%%time\n","model_2 = Ridge(alpha=1.0, random_state=1)\n","model_2.fit(X_train_new, y_train)"],"metadata":{"id":"6VLUbJiiDr3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_preds2 = model_2.predict(X_train_new)\n","valid_preds2 = model_2.predict(X_valid_new)\n","print('Ошибка на трейне:', mean_squared_error(y_train, train_preds2))\n","print('Ошибка на тесте:', mean_squared_error(y_valid, valid_preds2))"],"metadata":{"id":"e_KHqq6_D0I2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Важные замечания\n","1.\tПри выборе набора данных (data set) на ресурсах [3, 4] необходимо согласовать свой выбор с другими студентами группы и преподавателем с целью недопустимости выбора одинаковых вариантов.\n","2.\tВ рамках данного лабораторного курса рекомендуется использовать инструментарий Python (библиотеки, среду разработки) для решения поставленных задач.\n","\n","Индивидуальное задание\n","1.\tСтудент самостоятельно выбирает набор данных на ресурсах [3, 4] для построения классификатора с использованием метода логической классификации и согласует свой выбор с преподавателем.\n","2.\tВыполните построение модели классификации на основе дерева классификации. В ходе решения задачи необходимо решить следующие подзадачи:\n","2.1\tПостроение логического классификатора с заданием max_depth (максимальной глубины) и max_features (максимального количества признаков) пользователем (установить любые); визуализация дерева решений для выбранных исследователем параметров (в формате .png)\n","2.2\tВычисление оценки cross validation (MSE) для различнх значений max_depth (построить график зависимости);\n","2.3\tВычисление оценки cross validation (MSE) для различнх значений max_features (построить график зависимости);\n","2.4\tВычислите оптимальные значения max_depth и max_features. Обоснуйте свой выбор. Продемонстрируйте использование полученного классификатора.  \n","2.5\tВыведите дерево в формате .png;\n","2.6\tВыведите решающие границы полученной модели.\n","\n","Содержание отчета и его форма\n","\n","Отчет по лабораторной работе должен содержать:\n","1.\tНомер и название лабораторной работы; задачи лабораторной работы.\n","2.\tРеализация каждого пункта подраздела «Индивидуальное задание» с приведением исходного кода программы, диаграмм и графиков для визуализации данных.\n","3.\tОтветы на контрольные вопросы.\n","4.\tЭкранные формы (консольный вывод) и листинг программного кода с комментариями, показывающие порядок выполнения лабораторной работы, и результаты, полученные в ходе её выполнения.\n","Отчет о выполнении лабораторной работы сдается преподавателю.\n","\n","Контрольные вопросы\n","\n","1.\tКакие методы классификации являются линейными?\n","2.\tУкажите основные параметры линеймой модели классификации.\n","3.\tПоясните назначение и принципы реализации методов стахостического градиента.\n","4.\tВ чем заключается главная идея метода опорных векторов?\n","5.\tЧто такое «линейно разделимая выборка»?\n","6.\tПоясните назначение ядер и спрямляющих пространств в алгоритмах линейной классификации.\n","\n","Список литературы\n","\n","Для выполнения лабораторной работы, при подготовке к защите, а также для\n","ответа на контрольные вопросы рекомендуется использовать следующие источники: [1–5].\n"],"metadata":{"id":"Vift6dePEEgC"}}]}