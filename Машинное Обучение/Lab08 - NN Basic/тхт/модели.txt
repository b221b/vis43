добавь в этот код Использование tf.data.Dataset
Если вы еще не используете tf.data.Dataset, это может значительно ускорить загрузку и предварительную обработку данных.

import tensorflow as tf

# Пример создания tf.data.Dataset
train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.AUTOTUNE)

код:
```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.preprocessing import LabelEncoder

# Загрузка набора данных
data = pd.read_csv('exam_регр.csv', delimiter=';')

# Предположим, что мы классифицируем на основе mean_exam_points
# Для этого преобразуем mean_exam_points в категории
# Например, 0-50 - класс 0, 51-75 - класс 1, 76-100 - класс 2
bins = [0, 50, 75, 100]
labels = [0, 1, 2]
data['class'] = pd.cut(data['mean_exam_points'], bins=bins, labels=labels, right=True)


# Определяем признаки и целевую переменную
X = data[['age', 'years_of_experience', 'lesson_price', 'qualification', 'physics', 'chemistry', 'biology', 'english', 'geography', 'history']]
y = data['class'].values

# Кодирование категориальных переменных
label_encoders = {}
for column in X.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    X.loc[:, column] = le.fit_transform(X[column])  # Используем .loc для изменения значений
    label_encoders[column] = le


# Разделение данных на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Стандартизация данных
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

def create_model():
    model = keras.Sequential()
    model.add(layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)))
    model.add(layers.Dense(10, activation='relu'))
    model.add(layers.Dense(3, activation='softmax'))  # 3 класса
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Создание и обучение модели
model = create_model()
history = model.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=5)

# Оценка модели
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_accuracy:.4f}")

# Визуализация истории обучения
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

def create_model_improved():
    model = keras.Sequential()
    model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))  # Увеличение числа нейронов
    model.add(layers.Dropout(0.5))  # Слой Dropout для регуляризации
    model.add(layers.Dense(64, activation='relu'))  # Увеличение числа нейронов
    model.add(layers.Dense(32, activation='relu'))  # Новый скрытый слой
    model.add(layers.Dense(3, activation='softmax'))  # 3 класса
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Изменение скорости обучения
    return model


# Создание и обучение улучшенной модели
improved_model = create_model_improved()
history_improved = improved_model.fit(X_train, y_train, epochs=20, validation_split=0.2, batch_size=16)  # Увеличение числа эпох

# Оценка улучшенной модели
test_loss, test_accuracy = improved_model.evaluate(X_test, y_test)
print(f"Тестовая точность улучшенной модели: {test_accuracy:.4f}")

# Визуализация истории обучения улучшенной модели
plt.plot(history_improved.history['accuracy'], label='Train Accuracy')
plt.plot(history_improved.history['val_accuracy'], label='Validation Accuracy')
plt.title('Улучшенная точность модели')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

def create_model_improved_v2():
    model = keras.Sequential()
    model.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)))  # Увеличение числа нейронов
    model.add(layers.Dropout(0.5))  # Слой Dropout для регуляризации
    model.add(layers.Dense(128, activation='relu'))  # Увеличение числа нейронов
    model.add(layers.Dropout(0.5))  # Еще один слой Dropout
    model.add(layers.Dense(64, activation='relu'))  # Новый скрытый слой
    model.add(layers.Dense(3, activation='softmax'))  # 3 класса
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Изменение скорости обучения
    return model

# Создание и обучение улучшенной модели
improved_model_v2 = create_model_improved_v2()
history_improved_v2 = improved_model_v2.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=24)  # Увеличение числа эпох

# Оценка улучшенной модели
test_loss, test_accuracy = improved_model_v2.evaluate(X_test, y_test)
print(f"Тестовая точность улучшенной модели v2: {test_accuracy:.4f}")

# Визуализация истории обучения улучшенной модели
plt.plot(history_improved_v2.history['accuracy'], label='Train Accuracy')
plt.plot(history_improved_v2.history['val_accuracy'], label='Validation Accuracy')
plt.title('Улучшенная точность модели v2')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

def create_model_improved_v3():
    model = keras.Sequential()
    model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))  # Уменьшение числа нейронов
    model.add(layers.BatchNormalization())  # Добавление Batch Normalization
    model.add(layers.Dropout(0.3))  # Уменьшение Dropout
    model.add(layers.Dense(256, activation='relu'))  # Уменьшение числа нейронов
    model.add(layers.BatchNormalization())  # Добавление Batch Normalization
    model.add(layers.Dense(3, activation='softmax'))  # 3 класса
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Уменьшение скорости обучения
    return model

# Создание и обучение улучшенной модели
improved_model_v3 = create_model_improved_v3()
history_improved_v3 = improved_model_v3.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=32)  # Сохранение числа эпох

# Оценка улучшенной модели
test_loss, test_accuracy = improved_model_v3.evaluate(X_test, y_test)
print(f"Тестовая точность улучшенной модели v3: {test_accuracy:.4f}")

# Визуализация истории обучения улучшенной модели
plt.plot(history_improved_v3.history['accuracy'], label='Train Accuracy')
plt.plot(history_improved_v3.history['val_accuracy'], label='Validation Accuracy')
plt.title('Улучшенная точность модели v3')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
```